{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coastal-vanilla",
   "metadata": {},
   "source": [
    "# 1. About this Sprint\n",
    "\n",
    "## The purpose of this Sprint\n",
    "<li> Understand ensemble learning </li>\n",
    "\n",
    "## How to learn\n",
    "\n",
    "We will implement various methods of ensemble learning with scratch.\n",
    "\n",
    "# 2. Ensemble learning\n",
    "\n",
    "We will implement scratch implementation of three types of ensemble learning. Then check each effect on a smaller dataset.\n",
    "\n",
    "<li> Blending </li>\n",
    "<li> Bagging </li>\n",
    "<li> Stacking </li>\n",
    "\n",
    "\n",
    "## Preparing a small dataset\n",
    "\n",
    "Prepare the regression dataset that you used before.\n",
    "\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "\n",
    "Download train.csv and use SalePrice as the objective variable and GrLivArea and YearBuiltas explanatory variables.\n",
    "\n",
    "\n",
    "Divide train.csv into 80% for learning (train) and 20% for verification (val).\n",
    "\n",
    "## scikit-learn\n",
    "\n",
    "We recommend using a library such as scikit-learn for a single model rather than a scratch implementation.\n",
    "\n",
    "\n",
    "[sklearn.linear_model.LinearRegression — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "\n",
    "[sklearn.svm.SVR — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
    "\n",
    "\n",
    "[sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "# 3. Blending\n",
    "\n",
    "## Problem 1: Blending scratch mounting\n",
    "\n",
    "Show **at least three​ ​examples of scratch implementation of blending** that are more accurate than a single model. Higher accuracy means less mean squared error (MSE) on the validation data.\n",
    "\n",
    "## What is blending?\n",
    "\n",
    "Blending is a method of independently training N diverse models, weighting the estimation results, and then adding them together. The simplest is to take the average. Various models are created by changing the following conditions.\n",
    "\n",
    "<li>Techniques (eg linear regression, SVM, decision tree, neural network, etc.)</li>\n",
    "<li>Hyperparameters (eg SVM kernel type, initial weights, etc.)</li>\n",
    "<li>How to preprocess input data (eg standardization, logarithmic transformation, PCA, etc.)</li>\n",
    "\n",
    "\n",
    "The important thing is that each model is very different.\n",
    "\n",
    "\n",
    "Blending in regression problems is so simple that it is not provided in scikit-learn.\n",
    "\n",
    "\n",
    "<< **Supplement** >>\n",
    "\n",
    "\n",
    "In the case of a classification problem, a majority vote will be taken. Because it is more complicated than regression problems, scikit-learn provides a Voting Classifier.\n",
    "\n",
    "\n",
    "[sklearn.ensemble.VotingClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-inclusion",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "following-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-syntax",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "formal-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "breeding-metadata",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "roman-graphics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coastal-blocking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  YearBuilt\n",
       "0       1710       2003\n",
       "1       1262       1976\n",
       "2       1786       2001\n",
       "3       1717       1915\n",
       "4       2198       2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"GrLivArea\",\"YearBuilt\"]]\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "regional-manual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    208500\n",
       "1    181500\n",
       "2    223500\n",
       "3    140000\n",
       "4    250000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[\"SalePrice\"]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pacific-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), Y.to_numpy(), test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "exclusive-azerbaijan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (1460,)\n",
      "X (1460, 2)\n",
      "X_train (1095, 2)\n",
      "X_test (365, 2)\n",
      "y_train (1095,)\n",
      "y_test (365,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Y\",Y.shape)\n",
    "print(\"X\",X.shape)\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_test\",X_test.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cleared-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ranking-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_trans (1095, 2)\n",
      "X_test_trans (365, 2)\n",
      "y_train (1095,)\n",
      "y_test (365,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_trans\",X_train_trans.shape)\n",
    "print(\"X_test_trans\",X_test_trans.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-entry",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-melissa",
   "metadata": {},
   "source": [
    "### Single Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "mathematical-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error Linear Regression 2314465092.7320137\n",
      "Mean square error Decision Tree 2477516526.54551\n",
      "Mean square error SVR 7169177845.536933\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "svr = SVR()\n",
    "lr.fit(X_train_trans, y_train)\n",
    "dt.fit(X_train_trans, y_train)\n",
    "svr.fit(X_train_trans, y_train)\n",
    "y_pred_lr = lr.predict(X_test_trans)\n",
    "y_pred_dt = dt.predict(X_test_trans)\n",
    "y_pred_svr = svr.predict(X_test_trans)\n",
    "print(\"Mean square error Linear Regression\",mean_squared_error(y_test,y_pred_lr))\n",
    "print(\"Mean square error Decision Tree\",mean_squared_error(y_test,y_pred_dt))\n",
    "print(\"Mean square error SVR\",mean_squared_error(y_test,y_pred_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-manitoba",
   "metadata": {},
   "source": [
    "### Ensamble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "married-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blendding():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models = list()\n",
    "        self.blender = LinearRegression()\n",
    "        self.models.append(LinearRegression())\n",
    "        self.models.append(DecisionTreeRegressor())\n",
    "        self.models.append(SVR())\n",
    "    def fit(self, X_train, X_val, y_train, y_val):\n",
    "        meta_X = list()\n",
    "        for model in self.models:\n",
    "            # fit in training set\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict on hold out set\n",
    "            yhat = model.predict(X_val)\n",
    "            # reshape predictions into a matrix with one column\n",
    "            yhat = yhat.reshape(len(yhat), 1)\n",
    "            # store predictions as input for blending\n",
    "            meta_X.append(yhat)\n",
    "        # create 2d array from predictions, each set is an input feature\n",
    "        meta_X = hstack(meta_X)\n",
    "        self.blender.fit(meta_X, y_val)\n",
    "    def predict(self, X_test):\n",
    "        meta_X = list()\n",
    "        for model in self.models:\n",
    "            # predict with base model\n",
    "            yhat = model.predict(X_test)\n",
    "            # reshape predictions into a matrix with one column\n",
    "            yhat = yhat.reshape(len(yhat), 1)\n",
    "            # store prediction\n",
    "            meta_X.append(yhat)\n",
    "        # create 2d array from predictions, each set is an input feature\n",
    "        meta_X = hstack(meta_X)\n",
    "        # predict\n",
    "        return self.blender.predict(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eastern-craps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending Score 1869607264.7200263\n"
     ]
    }
   ],
   "source": [
    "blending_model = Blendding()\n",
    "blending_model.fit( X_train_trans, X_test_trans, y_train, y_test)\n",
    "y_pred_ensemble = blending_model.predict(X_test_trans)\n",
    "print(\"Blending Score\",mean_squared_error(y_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-memphis",
   "metadata": {},
   "source": [
    "### The result show that the essemble has smaller  Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-tablet",
   "metadata": {},
   "source": [
    "## Problem 2: Scratch mounting of bagging\n",
    "Please show at least one​ ​example where you scratch-implement the bagging and it is more accurate than a single model.\n",
    "\n",
    "## What is bagging?\n",
    "\n",
    "\n",
    "Bagging is a way to diversify how to select input data. N types of subsets (bootstrap samples) are created by randomly extracting from the training data after allowing duplication. N models are trained by them and the estimation results are averaged. Unlike blending, each weighting does not change.\n",
    "\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "\n",
    "Data can be split randomly by using scikit-learn's train_test_split with the shuffle parameter set to True. This will give you a bootstrap sample.\n",
    "\n",
    "\n",
    "The part that averages the estimation results is implemented in the same way as boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "together-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "class BaggingRegressor:\n",
    "    def __init__(self,number_model = 200,sample_size = 0.5):\n",
    "        self.models = [LinearRegression() for i in range(number_model)]\n",
    "        self.sample_size = sample_size\n",
    "    def fit(self,X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        for model in self.models:\n",
    "            sample_X , sample_y = self.subsample(X,y)\n",
    "            model.fit(sample_X,sample_y)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        result = 0\n",
    "        for model in self.models:\n",
    "            result += model.predict(X)\n",
    "        return result / len(self.models)\n",
    "    # Create a random subsample from the dataset with replacement\n",
    "    def subsample(self,X,y):\n",
    "        sample_X = list()\n",
    "        sample_y = list()\n",
    "        n_sample = round(len(X) * self.sample_size)\n",
    "        while len(sample_X) < n_sample:\n",
    "            index = random.randrange(len(X))\n",
    "            sample_X.append(X[index])\n",
    "            sample_y.append(y[index])\n",
    "        return np.array(sample_X) , np.array(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "arctic-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_model = BaggingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "collect-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_model.fit(X_train_trans,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "loose-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "soviet-advisory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_model.fit(X_train_trans,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "oriental-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_result = single_model.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "compact-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_result = ensamble_model.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "described-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Linear Regression 2314465092.7320137\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error Linear Regression',mean_squared_error(y_test, single_model_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "romantic-target",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Bagging: 2304942911.9577136\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error Bagging:',mean_squared_error(y_test, bagging_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-martial",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "## Problem 3: Stacking scratch mounting\n",
    "\n",
    "Please show at least one​ ​example where stacking is scratch-implemented and more accurate than a single model.\n",
    "\n",
    "## What is stacking?\n",
    "\n",
    "The stacking procedure is as follows. Stacking is possible if there is at least stage 0 and stage 1, so implement it. First, set about $K_0=3, M_0=2$.\n",
    "\n",
    "《**When learning**》\n",
    "\n",
    "(Stage $0$)\n",
    "\n",
    "<li> Divide the training data into $K_0$ pieces. </li>\n",
    "<li> The combination of $(K_0-1)$ pieces of the divided data can be made as learning data, and the remaining $1$ pieces can be made as estimation data to make $K_0$ pieces. </li>\n",
    "<li> Prepare $K_0$ instances of a model and learn using different learning data. </li>\n",
    "<li> For each trained model, input the remaining $1$ unused estimation data and obtain the estimated value. (This is called blend data) </li>\n",
    "<li> In addition, prepare $K_0$ instances of different models and do the same. If there are $M_0$ models, $M_0$ blend data can be obtained. </li>\n",
    "\n",
    "(Stage $n$)\n",
    "\n",
    "<li> Consider the blended data of stage $n-1$ as learning data having $M_{n-1}$ dimensional features and divide it into $K_n$ pieces. The same applies hereinafter.\n",
    "\n",
    "(Stage $N$) *Last stage\n",
    "\n",
    "<li> One kind of model is trained by using $M_{N-1}$ blended data of stage $N-1$ as input of $M_{N-1}$ dimensional features. This is the model that makes the final estimation.\n",
    "\n",
    "《**Estimated time**》\n",
    "    \n",
    "(Stage $0$)\n",
    "    \n",
    "<li> Input test data into $K_0 × M_0$ trained models and obtain $K_0 × M_0$ estimates. The average value is calculated on the $K_0$ axis, and data with $M_0$ dimensional features is obtained. (Called the blend test)\n",
    "\n",
    "(Stage $n$)\n",
    "    \n",
    "<li> Input the blend test obtained at stage $n-1$ into $K_n×M_n$ trained models and obtain $K_n×M_n$ estimates. The average value is calculated on the axis of $K_n$, and the data with the $M_0$-dimensional feature quantity is obtained. (Called the blend test)\n",
    "\n",
    "(Stage $N$) *Last stage\n",
    "    \n",
    "<li> Input the blend test obtained in the stage $N-1$ into the trained model to obtain the estimated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "blessed-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "metropolitan-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LinearRegression()\n",
    "    models['dt'] = DecisionTreeRegressor()\n",
    "    models['svm'] = SVR()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LinearRegression()))\n",
    "    level0.append(('dt', DecisionTreeRegressor()))\n",
    "    level0.append(('svm', SVR()))\n",
    "    # define meta learner model\n",
    "    level1 = LinearRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "single-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "administrative-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, names = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "analyzed-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr -2362134345.783 (1062051104.700)\n",
      ">dt -3833171660.947 (1784754247.536)\n",
      ">svm -7563001526.929 (3888030235.055)\n",
      ">stacking -2329858661.110 (1039956256.723)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_test_trans, y_test)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
