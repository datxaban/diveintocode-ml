{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thorough-civilian",
   "metadata": {},
   "source": [
    "# 1. About this Sprint\n",
    "\n",
    "## The purpose of this Sprint\n",
    "\n",
    "* Understanding decision trees through scratches\n",
    "* Get used to implementing complex algorithms\n",
    "\n",
    "## How to learn\n",
    "\n",
    "After implementing the decision tree with scratch, we will learn and verify it.\n",
    "\n",
    "# 2. What is decision tree learning?\n",
    "\n",
    "Decision tree learning is a machine learning method that creates a graph of a tree structure called a decision tree. In the field of machine learning, learning methods are also simply called \"decision trees.\"\n",
    "\n",
    "\n",
    "It can be used for both classification and regression, and in the case of classification, multi-value classification of 3 or more classes is possible. Only the basic classifications are dealt with here.\n",
    "\n",
    "## What is a decision tree?\n",
    "\n",
    "The decision tree is to repeat conditional branching on the data represented by the attribute / value pair {attribute 1: value 1, attribute 2: value 2, attribute 3: value 3, ..., attribute n: value n}. A tree-structured graph that can be assigned to a class.\n",
    "\n",
    "\n",
    "The following example is a graph assigned to the holding and canceling classes according to the attribute value of the venue temperature. You can classify by a decision tree by one conditional branch, \"whether the value of the attribute of the venue temperature is 35 or more\". For example, if 36 degrees is input to this decision tree, the output (judgment) of cancellation can be made.\n",
    "\n",
    "![decision tree](dt.png)\n",
    "\n",
    "In the field of machine learning, \"attributes and values\" are \"feature name and feature value\". From now on, it is simply called a feature quantity.\n",
    "\n",
    "## Various terms\n",
    "\n",
    "Let's look at some important terms in the decision tree with a slightly more complicated example. Let's consider the case of classifying whether an event is held or canceled by three types of features: \"rainfall\", \"whether indoors\", and \"wind strength\". By learning the training data, the following decision tree can be created.\n",
    "\n",
    "![decision tree](dt1.png)\n",
    "\n",
    "Each circled one is called a node. You can think of a parent-child relationship for a node. For example, the node (0) is called the parent node of the nodes (1) (2) (3). Conversely, the nodes (1), (2), and (3) are called child nodes of the node (0).​\n",
    "\n",
    "\n",
    "The top (0) is called the root node, and the node that represents the classification result such as (1) (4) (5) (7) (8) (9) at the end is called the leaf node.​\n",
    "\n",
    "\n",
    "The conditional arrow is called the edge.​ ​The depth is the number of edges from a node to the root node. The depth of (3) is 1, the depth of (6) is 2, the depth of (9) is 3, and so on. The maximum depth of this decision tree is 3.\n",
    "\n",
    "\n",
    "This is a multi-branch decision tree in which the three nodes (1), (2), and (3) are separated from (0), but in machine learning, the one that is divided into only two is unique. This is to reduce the complexity of learning.\n",
    "\n",
    "## How to make a decision tree\n",
    "\n",
    "There are many ways to learn a decision tree, but we'll scratch one of them.\n",
    "\n",
    "\n",
    "The decision tree created depends on the learning method, hyperparameters, and training data.\n",
    "\n",
    "## Think about estimation\n",
    "\n",
    "Will the event be held in the following cases? Use the decision tree to make a decision.\n",
    "\n",
    "| Rain fall\\[mm\\] | Whether indoors | Wind strength \\[m/s\\] |\n",
    "| --- | --- | --- |\n",
    "| 2.5 | 1(indoor) | 5 |\n",
    "\n",
    "The answer is \"hold\". Follow in the order of the red line below.\n",
    "![decision tree](dt2.png)\n",
    "This is the operation of estimation by the decision tree.\n",
    "\n",
    "## Features that can be handled\n",
    "\n",
    "The decision tree can theoretically handle not only quantitative variables but also categorical variables. However, the scikit-learn implementation only supports quantitative variables, so create a scratch implementation that way. In the above example, \"indoor and outdoor\" in \"Venue type\" is a categorical variable, but it can be handled by making it a quantitative variable such as \"0 and 1\" in \"whether indoor or not\".\n",
    "\n",
    "# 3. Decision tree scratch\n",
    "\n",
    "We will create a class of decision trees for classification by scratching. We will implement the algorithm using only the minimum library such as NumPy.\n",
    "\n",
    "\n",
    "​In the learning of the decision tree, a hyperparameter called the (maximum) depth that indicates how many times the conditional branch is repeated appears, but the implementation of depth 1 is an essential assignment. Those with a depth of 2 or more are considered as advanced assignment.\n",
    "\n",
    "\n",
    "There are various learning methods, but here we will implement based on the CART method, which is also used in scikit-learn.​ ​This method only splits the branch into two to reduce the complexity of learning.\n",
    "\n",
    "\n",
    "The template is prepared below. Add some code to this ScratchDecesionTreeClassifierDepth1 class.\n",
    "\n",
    "<<**Model**>>\n",
    "```\n",
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    Depth 1 decision tree classifier scratch implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程をoutputする場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Learn the decision tree classifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程をoutput\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the label using a decision tree classifier\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "```\n",
    "\n",
    "## Find the conditions for division by learning\n",
    "By learning, we ask under what conditions the nodes can be divided well.\n",
    "\n",
    "\n",
    "Calculate the Gini Impureness and Information Gain values for the node to determine if it is well separated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-claim",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seventh-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "appropriate-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRec():\n",
    "    def __init__(self,max_depth,min_size):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "    def fit(self,X,y):\n",
    "        train = np.concatenate([X,np.expand_dims(y,axis = 1)],axis = 1)\n",
    "        self.root = self.get_split(train)\n",
    "#         print(self.root)\n",
    "        self.split(self.root,self.max_depth,self.min_size,1)\n",
    "#         print(self.root)\n",
    "    def predict(self,X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            if x[self.root['index']] < self.root['value']:\n",
    "                if isinstance(self.root['left'], dict):\n",
    "                    predictions.append(self.predict_recur(self.root['left'], x))\n",
    "                else:\n",
    "                    predictions.append(self.root['left'])\n",
    "            else:\n",
    "                if isinstance(self.root['right'], dict):\n",
    "                    predictions.append(self.predict_recur(self.root['right'], x))\n",
    "                else:\n",
    "                    predictions.append(self.root['right'])\n",
    "        return np.array(predictions)\n",
    "    def predict_recur(self,node,X):\n",
    "        if X[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict_recur(node['left'], X)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict_recur(node['right'], X)\n",
    "            else:\n",
    "                return node['right']\n",
    "    def test_split(self,index,value,dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "    def gini_index(self,groups,classes):\n",
    "        # count all samples at split point\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = [row[-1] for row in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "    def get_split(self,dataset):\n",
    "        class_values = list(set(row[-1] for row in dataset))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        for index in range(len(dataset[0])-1):\n",
    "            for row in dataset:\n",
    "                groups = self.test_split(index, row[index], dataset)\n",
    "                gini = self.gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "    def to_terminal(self,group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "    def split(self,node,max_depth,min_size,depth):\n",
    "        left, right = node['groups']\n",
    "        del(node['groups'])\n",
    "        # check for a no split\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.to_terminal(left + right)\n",
    "            return\n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            return\n",
    "        # process left child\n",
    "        if len(left) <= min_size:\n",
    "            node['left'] = self.to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = self.get_split(left)\n",
    "            self.split(node['left'], max_depth, min_size, depth+1)\n",
    "        # process right child\n",
    "        if len(right) <= min_size:\n",
    "            node['right'] = self.to_terminal(right)\n",
    "        else:\n",
    "            node['right'] = self.get_split(right)\n",
    "            self.split(node['right'], max_depth, min_size, depth+1)\n",
    "    def print_tree(self,depth=0):\n",
    "        if isinstance(self.root, dict):\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (self.root['index']+1), self.root['value'])))\n",
    "            self.print_tree_rec(self.root['left'], depth+1)\n",
    "            self.print_tree_rec(self.root['right'], depth+1)\n",
    "        else:\n",
    "            print('%s[%s]' % ((depth*' ', self.root)))\n",
    "    def print_tree_rec(self,node,depth):\n",
    "        if isinstance(node, dict):\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "            self.print_tree_rec(node['left'], depth+1)\n",
    "            self.print_tree_rec(node['right'], depth+1)\n",
    "        else:\n",
    "            print('%s[%s]' % ((depth*' ', node)))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-breast",
   "metadata": {},
   "source": [
    "## Problem 1: Function for finding impureness\n",
    "Create a function to calculate the Gini impurity​​ ​of a node. For node t, the Gini impurity I(t) can be obtained by the following formula The more mixed the classes are, the higher the Gini impurity.\n",
    "  \n",
    "<center> $I(t) = 1 - \\sum_{i=1}^{K} P^{2}(C_i|t) = 1 - \\sum_{i=1}^{K} (\\frac{N_{t,i}}{N_{t,all}}) ^2$ </center>\n",
    "\n",
    "$t$: Index of nodes \\\n",
    "$i$: Index of classes \\\n",
    "$K$: Number of classes \\\n",
    "$C_i$: The i-th class \\\n",
    "$P(C_i|t)$: Proportion of C_i at the t-th node \\\n",
    "$N_{t,i}$: Number of samples belonging to the i-th class of the t-th node \\\n",
    "$N_{t,all}$: Total number of samples at the t-th node\n",
    "\n",
    "First, make a simple example and compare the results of the manual calculation with the function.\n",
    "\n",
    "<<**Example**>>\n",
    "* Class 1: Number of samples 15, Class 2: Number of samples 15 → Gini impure 0.500\n",
    "* Class 1: Number of samples 15, Class 2: Number of samples 15, Class 3: Number of samples 15 → Gini impure 0.667\n",
    "* Class 1: Number of samples 18, Class 2: Number of samples 12 → Gini impure 0.480\n",
    "* Class 1: Number of samples 30, Class 2: Number of samples 0 → Gini impure 0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-clone",
   "metadata": {},
   "source": [
    "## Problem 2: Function for finding information gain\n",
    "\n",
    "Next, create a function to calculate the **information gain** between the nodes. Gini Impurity **I(t)** created in Problem 1 **IG**,\n",
    "can be found by the following formula. The better the separation, the greater the information gain.\n",
    "\n",
    "Since there are only two branches here, the branch destination is called the \"left node / right node\".\n",
    "\n",
    "<center> $ IG(p) = I(p) - \\frac{N_{left,all}}{N_{p,all}} I(left) - \\frac{N_{right,all}}{N_{p,all}} I(right) $</center>\n",
    "\n",
    "$p$: Index indicating the parent node \\\n",
    "**left**: Index showing the left-hand node \\\n",
    "**right**: Index showing the nodes on the right \\\n",
    "\n",
    "First, make a simple example and compare the results of the manual calculation with the function.\n",
    "\n",
    "<<**Example**>>\n",
    "\n",
    "Left node class 1: Number of samples 10, Left node class 2: Number of samples 30, Right node class 1: Number of samples 20, Right node class 2: Number of samples 5 → Information gain 0.143"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-benefit",
   "metadata": {},
   "source": [
    "## Problem 3: Learning\n",
    "Write the code to split the space and generate a graph of the decision tree. Since it is a decision tree with a depth of 1, we will divide it only once. Generating a graph here means finding which feature quantity is more than how many as a condition for one division.\n",
    "\n",
    "\n",
    "All combinations of training data are divided, and the division that maximizes the information gain between nodes is recorded as the division criterion for that node.\n",
    "\n",
    "\n",
    "A node with zero impureness that does not mix classes, or a node with a specified depth is a **leaf node**. A class is recorded in the leaf node, and this is used as the class to be classified at the time of estimation. If the classes are not mixed, record the class as it is, and if it is mixed, decide by majority vote.\n",
    "\n",
    "\n",
    "<< **How to take a combination** >>\n",
    "\n",
    "\n",
    "The simplest way to take all combinations is to use the value of each feature as a threshold value for division. Use this method for this scratch on one end.\n",
    "\n",
    "\n",
    "Another method is to set an intermediate value as the threshold, and scikit-learn uses this method.\n",
    "\n",
    "\n",
    "<< **Supplement** >>\n",
    "\n",
    "\n",
    "The function for calculating the information gain in Problem 2 is not suitable for use in Problem 3, as it is not possible to calculate the impurity of the parent node \n",
    "$I(p)$\n",
    "is fixed, the same result can be obtained by simply summing the impurity of the left and right nodes. However, here the implementation should take into account the parent node and calculate the information gain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-argument",
   "metadata": {},
   "source": [
    "## Problem 4: Estimate\n",
    "Please implement the estimation mechanism. Add it to the predict method included in the template of the ScratchDecesionTreeClassifierDepth1 class.\n",
    "\n",
    "\n",
    "Judge the value of the input data under the learned conditions and see which leaf node is reached. Since the class is recorded in the leaf node, this is the estimate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-girlfriend",
   "metadata": {},
   "source": [
    "# 4. Verification\n",
    "\n",
    "## Problem 5: Learning and estimation\n",
    "Learn and estimate the scratch implementation for the binary classification of Simple Dataset 2 prepared in Sprint, an introduction to machine learning scratch.\n",
    "\n",
    "\n",
    "Compare this with the scikit-learn implementation and see if it works correctly.\n",
    "\n",
    "\n",
    "Use scikit-learn for indicator values such as Accuracy, Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "monetary-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n",
    "])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "threaded-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (40, 2)\n",
      "Y shape (40,)\n",
      "Train shape (40, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape\",X.shape)\n",
    "print(\"Y shape\",y.shape)\n",
    "train = np.concatenate([X,np.expand_dims(y,axis = 1)],axis = 1)\n",
    "print(\"Train shape\",train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "suburban-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DecisionTreeRec(max_depth=1,min_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "national-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "beneficial-edwards",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "figured-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 5.352]\n",
      " [0.0]\n",
      " [1.0]\n"
     ]
    }
   ],
   "source": [
    "my_model.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-right",
   "metadata": {},
   "source": [
    "## Problem 6: Visualization of decision area\n",
    "Visualise the decision area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "compatible-differential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "def decision_region(X, y, model, step=0.01, title='1 Node Decision Tree', xlabel='xlabel', ylabel='ylabel', target_names=['Class 0', 'Class 1']):\n",
    "    \"\"\"\n",
    "    Draw the determination area of the model that learned binary classification with two-dimensional features.\n",
    "    The background color is drawn from the estimated values of the trained model.\n",
    "    散布図の点はTraining dataまたはValidation dataである。\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        Feature value\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        label\n",
    "    model : object\n",
    "        Insert the installed model of the learned model\n",
    "    step : float, (default : 0.1)\n",
    "        Set the interval to calculate the estimate\n",
    "    title : str\n",
    "        Give the text of the graph Title\n",
    "    xlabel, ylabel : str\n",
    "        Give the text of the axis label\n",
    "    target_names= : list of str\n",
    "        Give a list of legends\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "decision_region(X,y,my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-reporter",
   "metadata": {},
   "source": [
    "# 5. Deeper decision tree\n",
    "\n",
    "## Problem 7: (Advance assignment) Creation of a decision tree classifier class with a depth of 2\n",
    "\n",
    "Create a decision tree classifier class ScratchDecesionTreeClassifierDepth2 with a depth of 2.\n",
    "\n",
    "\n",
    "Depth 2 means that the space is divided twice.\n",
    "\n",
    "\n",
    "《**Hint**》\n",
    "\n",
    "\n",
    "Treating each node as an instance makes it easier to extend to any depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "british-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_2_model = DecisionTreeRec(max_depth=2,min_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "respected-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_2_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "adjustable-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_2_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "gentle-express",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 5.352]\n",
      " [X2 < 2.546]\n",
      "  [0.0]\n",
      "  [0.0]\n",
      " [X1 < -0.122]\n",
      "  [1.0]\n",
      "  [1.0]\n"
     ]
    }
   ],
   "source": [
    "depth_2_model.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-details",
   "metadata": {},
   "source": [
    "## Problem 8: (Advance assignment) Creation of decision tree classifier class with unlimited depth\n",
    "Create a decision tree classifier class ScratchDecesionTreeClassifierDepthInf with unlimited depth.\n",
    "\n",
    "\n",
    "Allow any depth to be specified, otherwise allow all leaf nodes to continue until all Gini impureness is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "neural-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_inf_model = DecisionTreeRec(max_depth=np.inf,min_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "animal-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_inf_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "negative-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_inf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "industrial-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 5.352]\n",
      " [X2 < 2.546]\n",
      "  [X2 < -1.822]\n",
      "   [X1 < -1.462]\n",
      "    [X1 < -3.060]\n",
      "     [X1 < -3.594]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      "     [1.0]\n",
      "    [X1 < -0.447]\n",
      "     [X1 < -1.462]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      "     [0.0]\n",
      "   [X2 < 0.154]\n",
      "    [X2 < -0.723]\n",
      "     [X1 < -0.613]\n",
      "      [1.0]\n",
      "      [0.0]\n",
      "     [X1 < 0.351]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "    [X1 < 1.132]\n",
      "     [X1 < -3.111]\n",
      "      [1.0]\n",
      "      [X1 < 0.106]\n",
      "       [0.0]\n",
      "       [X1 < 0.106]\n",
      "        [0.0]\n",
      "        [0.0]\n",
      "     [1.0]\n",
      "  [X1 < -0.989]\n",
      "   [0.0]\n",
      "   [X1 < -0.989]\n",
      "    [0.0]\n",
      "    [0.0]\n",
      " [X1 < -0.122]\n",
      "  [X2 < 9.344]\n",
      "   [0.0]\n",
      "   [X1 < -1.281]\n",
      "    [1.0]\n",
      "    [1.0]\n",
      "  [X1 < 0.968]\n",
      "   [X1 < 0.546]\n",
      "    [1.0]\n",
      "    [1.0]\n",
      "   [1.0]\n"
     ]
    }
   ],
   "source": [
    "depth_inf_model.print_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
